{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Tool Agent"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (0.0.36)\n",
      "Requirement already satisfied: wikipedia in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (1.4.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from langchain-community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from langchain-community) (2.0.29)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from langchain-community) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from langchain-community) (0.6.5)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.48 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from langchain-community) (0.1.50)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from langchain-community) (0.1.54)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from langchain-community) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from langchain-community) (8.2.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from wikipedia) (4.12.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.48->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.48->langchain-community) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.48->langchain-community) (2.7.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from requests<3,>=2->langchain-community) (2024.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (4.11.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from beautifulsoup4->wikipedia) (2.5)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.48->langchain-community) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.48->langchain-community) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.48->langchain-community) (2.18.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv langchain-community wikipedia"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-05T18:47:32.848538400Z",
     "start_time": "2024-05-05T18:47:31.657536300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "model_path = os.getenv(\"MODEL_PATH\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-05T18:47:32.849538100Z",
     "start_time": "2024-05-05T18:47:32.841271600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 23 key-value pairs and 291 tensors from D:\\llm-models\\NousResearch\\Hermes-2-Pro-Llama-3-8B-GGUF\\Hermes-2-Pro-Llama-3-8B-Q8_0.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = Hermes-2-Pro-Llama-3-8B\n",
      "llama_model_loader: - kv   2:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   3:                       llama.context_length u32              = 8192\n",
      "llama_model_loader: - kv   4:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   7:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   8:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 7\n",
      "llama_model_loader: - kv  11:                           llama.vocab_size u32              = 128288\n",
      "llama_model_loader: - kv  12:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  13:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  14:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  15:                      tokenizer.ggml.tokens arr[str,128288]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  16:                  tokenizer.ggml.token_type arr[i32,128288]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  17:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  18:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  19:                tokenizer.ggml.eos_token_id u32              = 128003\n",
      "llama_model_loader: - kv  20:            tokenizer.ggml.padding_token_id u32              = 128001\n",
      "llama_model_loader: - kv  21:                    tokenizer.chat_template str              = {{bos_token}}{% for message in messag...\n",
      "llama_model_loader: - kv  22:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q8_0:  226 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 288/128288 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = BPE\n",
      "llm_load_print_meta: n_vocab          = 128288\n",
      "llm_load_print_meta: n_merges         = 280147\n",
      "llm_load_print_meta: n_ctx_train      = 8192\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 500000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 8192\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 8B\n",
      "llm_load_print_meta: model ftype      = Q8_0\n",
      "llm_load_print_meta: model params     = 8.03 B\n",
      "llm_load_print_meta: model size       = 7.95 GiB (8.50 BPW) \n",
      "llm_load_print_meta: general.name     = Hermes-2-Pro-Llama-3-8B\n",
      "llm_load_print_meta: BOS token        = 128000 '<|begin_of_text|>'\n",
      "llm_load_print_meta: EOS token        = 128003 '<|im_end|>'\n",
      "llm_load_print_meta: PAD token        = 128001 '<|end_of_text|>'\n",
      "llm_load_print_meta: LF token         = 128 'Ä'\n",
      "llm_load_print_meta: EOT token        = 128003 '<|im_end|>'\n",
      "llm_load_tensors: ggml ctx size =    0.30 MiB\n",
      "llm_load_tensors: offloading 32 repeating layers to GPU\n",
      "llm_load_tensors: offloading non-repeating layers to GPU\n",
      "llm_load_tensors: offloaded 33/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =   532.45 MiB\n",
      "llm_load_tensors:      CUDA0 buffer size =  7605.46 MiB\n",
      ".........................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 8192\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 500000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:      CUDA0 KV buffer size =  1024.00 MiB\n",
      "llama_new_context_with_model: KV self size  = 1024.00 MiB, K (f16):  512.00 MiB, V (f16):  512.00 MiB\n",
      "llama_new_context_with_model:  CUDA_Host  output buffer size =     0.49 MiB\n",
      "llama_new_context_with_model:      CUDA0 compute buffer size =   560.00 MiB\n",
      "llama_new_context_with_model:  CUDA_Host compute buffer size =    24.01 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 2\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'general.name': 'Hermes-2-Pro-Llama-3-8B', 'general.architecture': 'llama', 'llama.block_count': '32', 'llama.context_length': '8192', 'tokenizer.ggml.eos_token_id': '128003', 'general.file_type': '7', 'llama.attention.head_count_kv': '8', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.head_count': '32', 'llama.rope.freq_base': '500000.000000', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.vocab_size': '128288', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.model': 'gpt2', 'tokenizer.ggml.pre': 'llama-bpe', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '128000', 'tokenizer.ggml.padding_token_id': '128001', 'tokenizer.chat_template': \"{{bos_token}}{% for message in messages %}{{'<|im_start|>' + message['role'] + '\\n' + message['content'] + '<|im_end|>' + '\\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\\n' }}{% endif %}\"}\n",
      "Using gguf chat template: {{bos_token}}{% for message in messages %}{{'<|im_start|>' + message['role'] + '\n",
      "' + message['content'] + '<|im_end|>' + '\n",
      "'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n",
      "' }}{% endif %}\n",
      "Using chat eos_token: <|im_end|>\n",
      "Using chat bos_token: <|begin_of_text|>\n"
     ]
    }
   ],
   "source": [
    "from app.state.final_answer.factory import FinalAnswerNodeFactory\n",
    "from app.agent.base import BaseAgent\n",
    "from app.state.defaults import default_tools_handler, default_text_handler\n",
    "from app.state.node import Node\n",
    "from app.memory.memory import Memory\n",
    "from app.persona.persona import Persona\n",
    "from app.llm.generator import Generator\n",
    "from app.tools.langchain.wikipedia_query_run import LangchainWikipediaQueryRun\n",
    "from app.llm.llamacpp.service import LlamaCppService\n",
    "from typing import Dict, Any, Optional\n",
    "\n",
    "llm = LlamaCppService(model_path=model_path, n_gpu_layers=-1)\n",
    "tools = [LangchainWikipediaQueryRun(top_k_results=3, doc_content_chars_max=2048)]\n",
    "\n",
    "\n",
    "class SearchAgent(BaseAgent):\n",
    "    name = \"SearchAgent\"\n",
    "    description = \"Specializes in searching for information.\"\n",
    "    pass\n",
    "\n",
    "\n",
    "final_answer_state = FinalAnswerNodeFactory.get_node(Generator(\n",
    "    service=llm,\n",
    "    temperature=0.4,\n",
    "))\n",
    "\n",
    "search_results_key = \"search_results\"\n",
    "\n",
    "\n",
    "def search_filter_prompt_handler(persona: Persona, memory: Memory, _: Optional[Dict[str, Any]]) -> str:\n",
    "    messages_formatted = [f\"{message.name}: {message.content}\\n\" for message in memory.data.get_all_messages()]\n",
    "    search_results = memory.data.pop(search_results_key)\n",
    "    return f'''{persona.prompt()}\n",
    "\n",
    "Given the search results, filter out unrelated information that doesn't directly answer the problem. Return a summarized version of the search results with the most important details for the problem.\n",
    "\n",
    "Current Problem:\n",
    "\"\"\"\n",
    "{memory.data.get_current_message().content}\n",
    "\"\"\"\n",
    "\n",
    "Previous Messages:\n",
    "\"\"\"\n",
    "{messages_formatted}\n",
    "\"\"\"\n",
    "\n",
    "Search Results:\n",
    "\"\"\"\n",
    "{search_results}\n",
    "\"\"\"\n",
    "\n",
    "Give your summarized search results with the most important details for the problem.'''\n",
    "\n",
    "\n",
    "search_filter_node = Node(\n",
    "    state_name=\"search_filter\",\n",
    "    prompt_handler=search_filter_prompt_handler,\n",
    "    generation_handler=default_text_handler(\n",
    "        next_state=final_answer_state.state_name,\n",
    "        exclude_from_scratch_pad=False\n",
    "    ),\n",
    "    generator=Generator(\n",
    "        service=llm,\n",
    "        use_json_model=True,\n",
    "        temperature=0.1,\n",
    "    ),\n",
    "    tools=tools,\n",
    ")\n",
    "\n",
    "\n",
    "def search_prompt_handler(persona: Persona, memory: Memory, tool_schemas: Optional[Dict[str, Any]]) -> str:\n",
    "    messages_formatted = [f\"{message.name}: {message.content}\\n\" for message in memory.data.get_all_messages()]\n",
    "    return f'''{persona.prompt()}\n",
    "\n",
    "Search for information using your tools to help solve the following problem for the user. Use any previous messages as context.\n",
    "\n",
    "Current Problem:\n",
    "\"\"\"\n",
    "{memory.data.get_current_message().content}\n",
    "\"\"\"\n",
    "\n",
    "Previous Messages:\n",
    "\"\"\"\n",
    "{messages_formatted}\n",
    "\"\"\"\n",
    "\n",
    "Here are the schemas for the tools you have access to, pick only one:\n",
    "\"\"\"\n",
    "{tool_schemas}\n",
    "\"\"\"\n",
    "\n",
    "Respond with the JSON input for the tool of your choice to best solve the problem.'''\n",
    "\n",
    "\n",
    "search_node = Node(\n",
    "    state_name=\"search\",\n",
    "    prompt_handler=search_prompt_handler,\n",
    "    generation_handler=default_tools_handler(\n",
    "        next_state=search_filter_node.state_name,\n",
    "        exclude_from_scratch_pad=True,\n",
    "        save_data_key=search_results_key,\n",
    "    ),\n",
    "    generator=Generator(\n",
    "        service=llm,\n",
    "        use_json_model=True,\n",
    "        temperature=0.1,\n",
    "    ),\n",
    "    tools=tools,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-05T18:47:36.669821700Z",
     "start_time": "2024-05-05T18:47:32.848538400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-05T18:48:03.799815200Z",
     "start_time": "2024-05-05T18:47:36.667096800Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:app.agent.base:Agent SearchAgent:urn:uuid:89445e19-e121-4611-ae44-1ce9c43bfc1f received message: Query(goal='Who is the CEO of Microsoft?', initial_state='search', from_caller='user')\n",
      "INFO:app.agent.base:Agent SearchAgent:urn:uuid:89445e19-e121-4611-ae44-1ce9c43bfc1f executing state: search\n",
      "from_string grammar:\n",
      "root ::= object \n",
      "object ::= [{] ws object_11 [}] ws \n",
      "value ::= object | array | string | number | value_6 ws \n",
      "array ::= [[] ws array_15 []] ws \n",
      "string ::= [\"] string_18 [\"] ws \n",
      "number ::= number_19 number_25 number_29 ws \n",
      "value_6 ::= [t] [r] [u] [e] | [f] [a] [l] [s] [e] | [n] [u] [l] [l] \n",
      "ws ::= ws_31 \n",
      "object_8 ::= string [:] ws value object_10 \n",
      "object_9 ::= [,] ws string [:] ws value \n",
      "object_10 ::= object_9 object_10 | \n",
      "object_11 ::= object_8 | \n",
      "array_12 ::= value array_14 \n",
      "array_13 ::= [,] ws value \n",
      "array_14 ::= array_13 array_14 | \n",
      "array_15 ::= array_12 | \n",
      "string_16 ::= [^\"\\<U+0000>-<U+001F>] | [\\] string_17 \n",
      "string_17 ::= [\"\\/bfnrt] | [u] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] \n",
      "string_18 ::= string_16 string_18 | \n",
      "number_19 ::= number_20 number_21 \n",
      "number_20 ::= [-] | \n",
      "number_21 ::= [0-9] | [1-9] number_22 \n",
      "number_22 ::= [0-9] number_22 | \n",
      "number_23 ::= [.] number_24 \n",
      "number_24 ::= [0-9] number_24 | [0-9] \n",
      "number_25 ::= number_23 | \n",
      "number_26 ::= [eE] number_27 number_28 \n",
      "number_27 ::= [-+] | \n",
      "number_28 ::= [0-9] number_28 | [0-9] \n",
      "number_29 ::= number_26 | \n",
      "ws_30 ::= [ <U+0009><U+000A>] ws \n",
      "ws_31 ::= ws_30 | \n",
      "\n",
      "\n",
      "llama_print_timings:        load time =     140.99 ms\n",
      "llama_print_timings:      sample time =    1240.81 ms /    23 runs   (   53.95 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     140.72 ms /   236 tokens (    0.60 ms per token,  1677.08 tokens per second)\n",
      "llama_print_timings:        eval time =     395.99 ms /    22 runs   (   18.00 ms per token,    55.56 tokens per second)\n",
      "llama_print_timings:       total time =    1939.99 ms /   258 tokens\n",
      "INFO:app.agent.base:Agent SearchAgent:urn:uuid:89445e19-e121-4611-ae44-1ce9c43bfc1f executing state: search_filter\n",
      "from_string grammar:\n",
      "root ::= object \n",
      "object ::= [{] ws object_11 [}] ws \n",
      "value ::= object | array | string | number | value_6 ws \n",
      "array ::= [[] ws array_15 []] ws \n",
      "string ::= [\"] string_18 [\"] ws \n",
      "number ::= number_19 number_25 number_29 ws \n",
      "value_6 ::= [t] [r] [u] [e] | [f] [a] [l] [s] [e] | [n] [u] [l] [l] \n",
      "ws ::= ws_31 \n",
      "object_8 ::= string [:] ws value object_10 \n",
      "object_9 ::= [,] ws string [:] ws value \n",
      "object_10 ::= object_9 object_10 | \n",
      "object_11 ::= object_8 | \n",
      "array_12 ::= value array_14 \n",
      "array_13 ::= [,] ws value \n",
      "array_14 ::= array_13 array_14 | \n",
      "array_15 ::= array_12 | \n",
      "string_16 ::= [^\"\\<U+0000>-<U+001F>] | [\\] string_17 \n",
      "string_17 ::= [\"\\/bfnrt] | [u] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] \n",
      "string_18 ::= string_16 string_18 | \n",
      "number_19 ::= number_20 number_21 \n",
      "number_20 ::= [-] | \n",
      "number_21 ::= [0-9] | [1-9] number_22 \n",
      "number_22 ::= [0-9] number_22 | \n",
      "number_23 ::= [.] number_24 \n",
      "number_24 ::= [0-9] number_24 | [0-9] \n",
      "number_25 ::= number_23 | \n",
      "number_26 ::= [eE] number_27 number_28 \n",
      "number_27 ::= [-+] | \n",
      "number_28 ::= [0-9] number_28 | [0-9] \n",
      "number_29 ::= number_26 | \n",
      "ws_30 ::= [ <U+0009><U+000A>] ws \n",
      "ws_31 ::= ws_30 | \n",
      "\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     140.99 ms\n",
      "llama_print_timings:      sample time =    3045.04 ms /    56 runs   (   54.38 ms per token,    18.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     411.89 ms /   543 tokens (    0.76 ms per token,  1318.30 tokens per second)\n",
      "llama_print_timings:        eval time =    1310.89 ms /    55 runs   (   23.83 ms per token,    41.96 tokens per second)\n",
      "llama_print_timings:       total time =    5164.20 ms /   598 tokens\n",
      "INFO:app.agent.base:Agent SearchAgent:urn:uuid:89445e19-e121-4611-ae44-1ce9c43bfc1f executing state: final_answer\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     140.99 ms\n",
      "llama_print_timings:      sample time =      11.71 ms /    43 runs   (    0.27 ms per token,  3673.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     118.86 ms /   103 tokens (    1.15 ms per token,   866.56 tokens per second)\n",
      "llama_print_timings:        eval time =     791.46 ms /    42 runs   (   18.84 ms per token,    53.07 tokens per second)\n",
      "llama_print_timings:       total time =    1139.35 ms /   145 tokens\n",
      "INFO:app.agent.base:Agent SearchAgent:urn:uuid:89445e19-e121-4611-ae44-1ce9c43bfc1f finished execution.\n",
      "INFO:app.agent.base:Agent SearchAgent:urn:uuid:89445e19-e121-4611-ae44-1ce9c43bfc1f received message: Query(goal='Where are they from?', initial_state='search', from_caller='user')\n",
      "INFO:app.agent.base:Agent SearchAgent:urn:uuid:89445e19-e121-4611-ae44-1ce9c43bfc1f executing state: search\n",
      "from_string grammar:\n",
      "root ::= object \n",
      "object ::= [{] ws object_11 [}] ws \n",
      "value ::= object | array | string | number | value_6 ws \n",
      "array ::= [[] ws array_15 []] ws \n",
      "string ::= [\"] string_18 [\"] ws \n",
      "number ::= number_19 number_25 number_29 ws \n",
      "value_6 ::= [t] [r] [u] [e] | [f] [a] [l] [s] [e] | [n] [u] [l] [l] \n",
      "ws ::= ws_31 \n",
      "object_8 ::= string [:] ws value object_10 \n",
      "object_9 ::= [,] ws string [:] ws value \n",
      "object_10 ::= object_9 object_10 | \n",
      "object_11 ::= object_8 | \n",
      "array_12 ::= value array_14 \n",
      "array_13 ::= [,] ws value \n",
      "array_14 ::= array_13 array_14 | \n",
      "array_15 ::= array_12 | \n",
      "string_16 ::= [^\"\\<U+0000>-<U+001F>] | [\\] string_17 \n",
      "string_17 ::= [\"\\/bfnrt] | [u] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] \n",
      "string_18 ::= string_16 string_18 | \n",
      "number_19 ::= number_20 number_21 \n",
      "number_20 ::= [-] | \n",
      "number_21 ::= [0-9] | [1-9] number_22 \n",
      "number_22 ::= [0-9] number_22 | \n",
      "number_23 ::= [.] number_24 \n",
      "number_24 ::= [0-9] number_24 | [0-9] \n",
      "number_25 ::= number_23 | \n",
      "number_26 ::= [eE] number_27 number_28 \n",
      "number_27 ::= [-+] | \n",
      "number_28 ::= [0-9] number_28 | [0-9] \n",
      "number_29 ::= number_26 | \n",
      "ws_30 ::= [ <U+0009><U+000A>] ws \n",
      "ws_31 ::= ws_30 | \n",
      "\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"name\": \"search\",\n",
      "    \"prompt\": \"You're an autonomous agent who solves problems in natural language. Use your knowledge to best answer the question.\\n\\nSearch for information using your tools to help solve the following problem for the user. Use any previous messages as context.\\n\\nCurrent Problem:\\n\\\"\\\"\\\"\\nWho is the CEO of Microsoft?\\n\\\"\\\"\\\"\\n\\nPrevious Messages:\\n\\\"\\\"\\\"\\n['user: Who is the CEO of Microsoft?\\\\n']\\n\\\"\\\"\\\"\\n\\nHere are the schemas for the tools you have access to, pick only one:\\n\\\"\\\"\\\"\\n[{'tool_name': 'wikipedia_query_run', 'tool_description': 'A tool for querying the Wikipedia API.', 'tool_parameters': {'description': 'The input to search for factual information on Wikipedia.', 'properties': {'tool_name': {'description': 'The name of the tool you choose to use.', 'title': 'Tool Name', 'type': 'string'}, 'query': {'title': 'Query', 'type': 'string'}}, 'required': ['tool_name', 'query'], 'title': 'WikipediaQueryInput', 'type': 'object'}}]\\n\\\"\\\"\\\"\\n\\nRespond with the JSON input for the tool of your choice to best solve the problem.\",\n",
      "    \"output\": \"Tool input: {\\n  \\\"tool_name\\\": \\\"wikipedia_query_run\\\",\\n  \\\"query\\\": \\\"CEO of Microsoft\\\"\\n}\\nTool output: {\\\"tool_name\\\":\\\"wikipedia_query_run\\\",\\\"output\\\":\\\"Page: Satya Nadella\\\\nSummary: Satya Narayana Nadella (; born 19 August 1967) is an Indian-American business executive. He is the executive chairman and CEO of Microsoft, succeeding Steve Ballmer in 2014 as CEO and John W. Thompson in 2021 as chairman. Before becoming CEO, he was the executive vice president of Microsoft's cloud and enterprise group, responsible for building and running the company's computing platforms.\\\\n\\\\n\\\\n\\\\nPage: Microsoft Gaming\\\\nSummary: Microsoft Gaming is an American multinational video game and digital entertainment division of Microsoft based in Redmond, Washington established in 2022. It produces the Xbox video game consoles and services, in addition to overseeing production and sales, and is led by CEO Phil Spencer, who oversaw Xbox since 2014. Its five development and publishing labels consist of: Xbox Game Studios, Bethesda Softworks (publisher of ZeniMax Media), Activision, Blizzard Entertainment, and King (aforementioned are publishers of Activision Blizzard).\\\\nPrior to 2022, Microsoft had several different video game-related product lines, including Xbox hardware, Xbox operations, and game development studios. Microsoft Gaming was created with the announcement of Microsoft's plans to acquire Activision Blizzard to unify all of Microsoft's gaming groups within a single division. With the completion of the Activision Blizzard acquisition in 2023, Microsoft became one of the largest gaming companies, the third-by revenue and the largest by employment. \\\\nThe division owns Intellectual property for some of the most popular, best-selling, and highest-grossing media franchises of all time, including Call of Duty, Candy Crush, Warcraft, Halo, Minecraft, and The Elder Scrolls.\\\\n\\\\n\\\\n\\\\nPage: Phil Spencer (business executive)\\\\nSummary: Phil Spencer (born January 12, 1968) is an American business executive and the CEO of Microsoft Gaming. Starting his career at Microsoft as an intern in 1988, Spencer has worked in various sectors within the company, including developing Microsoft's first CD-ROM-based title\\\"}\",\n",
      "    \"next\": \"search_filter\",\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 22,\n",
      "      \"prompt_tokens\": 236,\n",
      "      \"total_tokens\": 258\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"search_filter\",\n",
      "    \"prompt\": \"You're an autonomous agent who solves problems in natural language. Use your knowledge to best answer the question.\\n\\nGiven the search results, filter out unrelated information that doesn't directly answer the problem. Return a summarized version of the search results with the most important details for the problem.\\n\\nCurrent Problem:\\n\\\"\\\"\\\"\\nWho is the CEO of Microsoft?\\n\\\"\\\"\\\"\\n\\nPrevious Messages:\\n\\\"\\\"\\\"\\n['user: Who is the CEO of Microsoft?\\\\n']\\n\\\"\\\"\\\"\\n\\nSearch Results:\\n\\\"\\\"\\\"\\nTool input: {\\n  \\\"tool_name\\\": \\\"wikipedia_query_run\\\",\\n  \\\"query\\\": \\\"CEO of Microsoft\\\"\\n}\\nTool output: {\\\"tool_name\\\":\\\"wikipedia_query_run\\\",\\\"output\\\":\\\"Page: Satya Nadella\\\\nSummary: Satya Narayana Nadella (; born 19 August 1967) is an Indian-American business executive. He is the executive chairman and CEO of Microsoft, succeeding Steve Ballmer in 2014 as CEO and John W. Thompson in 2021 as chairman. Before becoming CEO, he was the executive vice president of Microsoft's cloud and enterprise group, responsible for building and running the company's computing platforms.\\\\n\\\\n\\\\n\\\\nPage: Microsoft Gaming\\\\nSummary: Microsoft Gaming is an American multinational video game and digital entertainment division of Microsoft based in Redmond, Washington established in 2022. It produces the Xbox video game consoles and services, in addition to overseeing production and sales, and is led by CEO Phil Spencer, who oversaw Xbox since 2014. Its five development and publishing labels consist of: Xbox Game Studios, Bethesda Softworks (publisher of ZeniMax Media), Activision, Blizzard Entertainment, and King (aforementioned are publishers of Activision Blizzard).\\\\nPrior to 2022, Microsoft had several different video game-related product lines, including Xbox hardware, Xbox operations, and game development studios. Microsoft Gaming was created with the announcement of Microsoft's plans to acquire Activision Blizzard to unify all of Microsoft's gaming groups within a single division. With the completion of the Activision Blizzard acquisition in 2023, Microsoft became one of the largest gaming companies, the third-by revenue and the largest by employment. \\\\nThe division owns Intellectual property for some of the most popular, best-selling, and highest-grossing media franchises of all time, including Call of Duty, Candy Crush, Warcraft, Halo, Minecraft, and The Elder Scrolls.\\\\n\\\\n\\\\n\\\\nPage: Phil Spencer (business executive)\\\\nSummary: Phil Spencer (born January 12, 1968) is an American business executive and the CEO of Microsoft Gaming. Starting his career at Microsoft as an intern in 1988, Spencer has worked in various sectors within the company, including developing Microsoft's first CD-ROM-based title\\\"}\\n\\\"\\\"\\\"\\n\\nGive your summarized search results with the most important details for the problem.\",\n",
      "    \"output\": \"{\\n  \\\"tool_name\\\": \\\"wikipedia_query_run\\\",\\n  \\\"output\\\": \\\"Satya Narayana Nadella is the current CEO of Microsoft. He succeeded Steve Ballmer in 2014 as CEO and John W. Thompson in 2021 as chairman.\\\"\\n}\",\n",
      "    \"next\": \"final_answer\",\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 55,\n",
      "      \"prompt_tokens\": 569,\n",
      "      \"total_tokens\": 624\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"final_answer\",\n",
      "    \"prompt\": \"You're an autonomous agent who solves problems in natural language. Use your knowledge to best answer the question.\\n\\nGiven the problem from the user, use your notes to give an answer. Directly address the problems.\\n\\nProblem:\\n\\\"\\\"\\\"\\nWho is the CEO of Microsoft?\\n\\\"\\\"\\\"\\n\\nNotes:\\n\\\"\\\"\\\"\\n\\nsearch_filter: {\\n  \\\"tool_name\\\": \\\"wikipedia_query_run\\\",\\n  \\\"output\\\": \\\"Satya Narayana Nadella is the current CEO of Microsoft. He succeeded Steve Ballmer in 2014 as CEO and John W. Thompson in 2021 as chairman.\\\"\\n}\\n\\\"\\\"\\\"\\n\\nYour answer to the problem.\",\n",
      "    \"output\": \"The current CEO of Microsoft is Satya Narayana Nadella, who took over from Steve Ballmer in 2014. Additionally, he also succeeded John W. Thompson as chairman in 2021.\",\n",
      "    \"next\": \"exit\",\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 42,\n",
      "      \"prompt_tokens\": 131,\n",
      "      \"total_tokens\": 173\n",
      "    }\n",
      "  }\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     140.99 ms\n",
      "llama_print_timings:      sample time =    1448.82 ms /    27 runs   (   53.66 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     100.33 ms /   266 tokens (    0.38 ms per token,  2651.30 tokens per second)\n",
      "llama_print_timings:        eval time =     486.80 ms /    26 runs   (   18.72 ms per token,    53.41 tokens per second)\n",
      "llama_print_timings:       total time =    2217.88 ms /   292 tokens\n",
      "C:\\Users\\Alexander\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\assemble-qevGTaVi-py3.11\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file C:\\Users\\Alexander\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\assemble-qevGTaVi-py3.11\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n",
      "INFO:app.agent.base:Agent SearchAgent:urn:uuid:89445e19-e121-4611-ae44-1ce9c43bfc1f executing state: search_filter\n",
      "from_string grammar:\n",
      "root ::= object \n",
      "object ::= [{] ws object_11 [}] ws \n",
      "value ::= object | array | string | number | value_6 ws \n",
      "array ::= [[] ws array_15 []] ws \n",
      "string ::= [\"] string_18 [\"] ws \n",
      "number ::= number_19 number_25 number_29 ws \n",
      "value_6 ::= [t] [r] [u] [e] | [f] [a] [l] [s] [e] | [n] [u] [l] [l] \n",
      "ws ::= ws_31 \n",
      "object_8 ::= string [:] ws value object_10 \n",
      "object_9 ::= [,] ws string [:] ws value \n",
      "object_10 ::= object_9 object_10 | \n",
      "object_11 ::= object_8 | \n",
      "array_12 ::= value array_14 \n",
      "array_13 ::= [,] ws value \n",
      "array_14 ::= array_13 array_14 | \n",
      "array_15 ::= array_12 | \n",
      "string_16 ::= [^\"\\<U+0000>-<U+001F>] | [\\] string_17 \n",
      "string_17 ::= [\"\\/bfnrt] | [u] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] \n",
      "string_18 ::= string_16 string_18 | \n",
      "number_19 ::= number_20 number_21 \n",
      "number_20 ::= [-] | \n",
      "number_21 ::= [0-9] | [1-9] number_22 \n",
      "number_22 ::= [0-9] number_22 | \n",
      "number_23 ::= [.] number_24 \n",
      "number_24 ::= [0-9] number_24 | [0-9] \n",
      "number_25 ::= number_23 | \n",
      "number_26 ::= [eE] number_27 number_28 \n",
      "number_27 ::= [-+] | \n",
      "number_28 ::= [0-9] number_28 | [0-9] \n",
      "number_29 ::= number_26 | \n",
      "ws_30 ::= [ <U+0009><U+000A>] ws \n",
      "ws_31 ::= ws_30 | \n",
      "\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     140.99 ms\n",
      "llama_print_timings:      sample time =    5053.95 ms /    92 runs   (   54.93 ms per token,    18.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     241.33 ms /   315 tokens (    0.77 ms per token,  1305.29 tokens per second)\n",
      "llama_print_timings:        eval time =    2058.84 ms /    91 runs   (   22.62 ms per token,    44.20 tokens per second)\n",
      "llama_print_timings:       total time =    7992.11 ms /   406 tokens\n",
      "INFO:app.agent.base:Agent SearchAgent:urn:uuid:89445e19-e121-4611-ae44-1ce9c43bfc1f executing state: final_answer\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     140.99 ms\n",
      "llama_print_timings:      sample time =      26.68 ms /    94 runs   (    0.28 ms per token,  3523.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     143.13 ms /   242 tokens (    0.59 ms per token,  1690.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1627.33 ms /    93 runs   (   17.50 ms per token,    57.15 tokens per second)\n",
      "llama_print_timings:       total time =    2274.05 ms /   335 tokens\n",
      "INFO:app.agent.base:Agent SearchAgent:urn:uuid:89445e19-e121-4611-ae44-1ce9c43bfc1f finished execution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"name\": \"search\",\n",
      "    \"prompt\": \"You're an autonomous agent who solves problems in natural language. Use your knowledge to best answer the question.\\n\\nSearch for information using your tools to help solve the following problem for the user. Use any previous messages as context.\\n\\nCurrent Problem:\\n\\\"\\\"\\\"\\nWhere are they from?\\n\\\"\\\"\\\"\\n\\nPrevious Messages:\\n\\\"\\\"\\\"\\n['user: Who is the CEO of Microsoft?\\\\n', 'SearchAgent: The current CEO of Microsoft is Satya Narayana Nadella, who took over from Steve Ballmer in 2014. Additionally, he also succeeded John W. Thompson as chairman in 2021.\\\\n', 'user: Where are they from?\\\\n']\\n\\\"\\\"\\\"\\n\\nHere are the schemas for the tools you have access to, pick only one:\\n\\\"\\\"\\\"\\n[{'tool_name': 'wikipedia_query_run', 'tool_description': 'A tool for querying the Wikipedia API.', 'tool_parameters': {'description': 'The input to search for factual information on Wikipedia.', 'properties': {'tool_name': {'description': 'The name of the tool you choose to use.', 'title': 'Tool Name', 'type': 'string'}, 'query': {'title': 'Query', 'type': 'string'}}, 'required': ['tool_name', 'query'], 'title': 'WikipediaQueryInput', 'type': 'object'}}]\\n\\\"\\\"\\\"\\n\\nRespond with the JSON input for the tool of your choice to best solve the problem.\",\n",
      "    \"output\": \"Tool input: {\\n  \\\"tool_name\\\": \\\"wikipedia_query_run\\\",\\n  \\\"query\\\": \\\"Satya Narayana Nadella\\\"\\n}\\nTool output: {\\\"tool_name\\\":\\\"wikipedia_query_run\\\",\\\"output\\\":\\\"Page: Satya Nadella\\\\nSummary: Satya Narayana Nadella (; born 19 August 1967) is an Indian-American business executive. He is the executive chairman and CEO of Microsoft, succeeding Steve Ballmer in 2014 as CEO and John W. Thompson in 2021 as chairman. Before becoming CEO, he was the executive vice president of Microsoft's cloud and enterprise group, responsible for building and running the company's computing platforms.\\\\n\\\\n\\\\n\\\\nPage: List of Manipal Academy of Higher Education alumni\\\\nSummary: Manipal Academy of Higher Education has produced many alumni from engineering to science to literature.\\\"}\",\n",
      "    \"next\": \"search_filter\",\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 26,\n",
      "      \"prompt_tokens\": 292,\n",
      "      \"total_tokens\": 318\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"search_filter\",\n",
      "    \"prompt\": \"You're an autonomous agent who solves problems in natural language. Use your knowledge to best answer the question.\\n\\nGiven the search results, filter out unrelated information that doesn't directly answer the problem. Return a summarized version of the search results with the most important details for the problem.\\n\\nCurrent Problem:\\n\\\"\\\"\\\"\\nWhere are they from?\\n\\\"\\\"\\\"\\n\\nPrevious Messages:\\n\\\"\\\"\\\"\\n['user: Who is the CEO of Microsoft?\\\\n', 'SearchAgent: The current CEO of Microsoft is Satya Narayana Nadella, who took over from Steve Ballmer in 2014. Additionally, he also succeeded John W. Thompson as chairman in 2021.\\\\n', 'user: Where are they from?\\\\n']\\n\\\"\\\"\\\"\\n\\nSearch Results:\\n\\\"\\\"\\\"\\nTool input: {\\n  \\\"tool_name\\\": \\\"wikipedia_query_run\\\",\\n  \\\"query\\\": \\\"Satya Narayana Nadella\\\"\\n}\\nTool output: {\\\"tool_name\\\":\\\"wikipedia_query_run\\\",\\\"output\\\":\\\"Page: Satya Nadella\\\\nSummary: Satya Narayana Nadella (; born 19 August 1967) is an Indian-American business executive. He is the executive chairman and CEO of Microsoft, succeeding Steve Ballmer in 2014 as CEO and John W. Thompson in 2021 as chairman. Before becoming CEO, he was the executive vice president of Microsoft's cloud and enterprise group, responsible for building and running the company's computing platforms.\\\\n\\\\n\\\\n\\\\nPage: List of Manipal Academy of Higher Education alumni\\\\nSummary: Manipal Academy of Higher Education has produced many alumni from engineering to science to literature.\\\"}\\n\\\"\\\"\\\"\\n\\nGive your summarized search results with the most important details for the problem.\",\n",
      "    \"output\": \"{\\n  \\\"tool_name\\\": \\\"wikipedia_query_run\\\",\\n  \\\"output\\\": \\\"Satya Narayana Nadella is an Indian-American business executive and the current CEO of Microsoft since 2014, succeeding Steve Ballmer. He also became chairman in 2021, succeeding John W. Thompson. Before his role as CEO, he was responsible for building and running Microsoft's computing platforms as the executive vice president of its cloud and enterprise group.\\\"\\n}\",\n",
      "    \"next\": \"final_answer\",\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 91,\n",
      "      \"prompt_tokens\": 341,\n",
      "      \"total_tokens\": 432\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"final_answer\",\n",
      "    \"prompt\": \"You're an autonomous agent who solves problems in natural language. Use your knowledge to best answer the question.\\n\\nGiven the problem from the user, use your notes to give an answer. Directly address the problems.\\n\\nProblem:\\n\\\"\\\"\\\"\\nWhere are they from?\\n\\\"\\\"\\\"\\n\\nNotes:\\n\\\"\\\"\\\"\\n\\nsearch_filter: {\\n  \\\"tool_name\\\": \\\"wikipedia_query_run\\\",\\n  \\\"output\\\": \\\"Satya Narayana Nadella is the current CEO of Microsoft. He succeeded Steve Ballmer in 2014 as CEO and John W. Thompson in 2021 as chairman.\\\"\\n}\\n- final_answer: The current CEO of Microsoft is Satya Narayana Nadella, who took over from Steve Ballmer in 2014. Additionally, he also succeeded John W. Thompson as chairman in 2021.\\n- search_filter: {\\n  \\\"tool_name\\\": \\\"wikipedia_query_run\\\",\\n  \\\"output\\\": \\\"Satya Narayana Nadella is an Indian-American business executive and the current CEO of Microsoft since 2014, succeeding Steve Ballmer. He also became chairman in 2021, succeeding John W. Thompson. Before his role as CEO, he was responsible for building and running Microsoft's computing platforms as the executive vice president of its cloud and enterprise group.\\\"\\n}\\n\\\"\\\"\\\"\\n\\nYour answer to the problem.\",\n",
      "    \"output\": \"The person you are referring to is Satya Narayana Nadella, who is from India but holds an Indian-American nationality. He has been the CEO of Microsoft since 2014, succeeding Steve Ballmer in that role. Additionally, he took over as chairman from John W. Thompson in 2021. Prior to his current positions, Nadella was responsible for building and running Microsoft's computing platforms as the executive vice president of its cloud and enterprise group.\",\n",
      "    \"next\": \"exit\",\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 93,\n",
      "      \"prompt_tokens\": 270,\n",
      "      \"total_tokens\": 363\n",
      "    }\n",
      "  }\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from app.agent.messages import Query\n",
    "import logging\n",
    "import json\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "persona = Persona(\n",
    "    description=\"You're an autonomous agent who solves problems in natural language. Use your knowledge to best answer the question.\")\n",
    "\n",
    "agent = SearchAgent.start(\n",
    "    persona=persona,\n",
    "    memory=Memory(),\n",
    "    nodes=[\n",
    "        search_filter_node,\n",
    "        search_node,\n",
    "        final_answer_state\n",
    "    ],\n",
    "    default_initial_state=\"search\")\n",
    "\n",
    "future = agent.ask(Query(initial_state=\"search\",\n",
    "                         goal=\"Who is the CEO of Microsoft?\"))\n",
    "response = future.get(timeout=30)\n",
    "print(json.dumps([step.model_dump() for step in response.steps], indent=2))\n",
    "\n",
    "future = agent.ask(Query(initial_state=\"search\",\n",
    "                         goal=\"Where are they from?\"))\n",
    "response = future.get(timeout=30)\n",
    "print(json.dumps([step.model_dump() for step in response.steps], indent=2))\n",
    "\n",
    "agent.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mermaid-py in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (0.5.0)\n",
      "Requirement already satisfied: ipython<9.0.0,>=8.17.2 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from mermaid-py) (8.24.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from mermaid-py) (2.31.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from ipython<9.0.0,>=8.17.2->mermaid-py) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from ipython<9.0.0,>=8.17.2->mermaid-py) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from ipython<9.0.0,>=8.17.2->mermaid-py) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from ipython<9.0.0,>=8.17.2->mermaid-py) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from ipython<9.0.0,>=8.17.2->mermaid-py) (2.18.0)\n",
      "Requirement already satisfied: stack-data in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from ipython<9.0.0,>=8.17.2->mermaid-py) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from ipython<9.0.0,>=8.17.2->mermaid-py) (5.14.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from ipython<9.0.0,>=8.17.2->mermaid-py) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from ipython<9.0.0,>=8.17.2->mermaid-py) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from requests<3.0.0,>=2.31.0->mermaid-py) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from requests<3.0.0,>=2.31.0->mermaid-py) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from requests<3.0.0,>=2.31.0->mermaid-py) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from requests<3.0.0,>=2.31.0->mermaid-py) (2024.2.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from jedi>=0.16->ipython<9.0.0,>=8.17.2->mermaid-py) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython<9.0.0,>=8.17.2->mermaid-py) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from stack-data->ipython<9.0.0,>=8.17.2->mermaid-py) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from stack-data->ipython<9.0.0,>=8.17.2->mermaid-py) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from stack-data->ipython<9.0.0,>=8.17.2->mermaid-py) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from asttokens>=2.1.0->stack-data->ipython<9.0.0,>=8.17.2->mermaid-py) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install mermaid-py"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-05T18:48:04.867955400Z",
     "start_time": "2024-05-05T18:48:03.795324400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "<mermaid._main.Mermaid at 0x8128b10>",
      "text/html": "<svg id=\"mermaid-svg\" width=\"100%\" xmlns=\"http://www.w3.org/2000/svg\" style=\"max-width: 122.375px;\" viewBox=\"-8 -8 122.375 386\" role=\"graphics-document document\" aria-roledescription=\"flowchart-v2\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><style xmlns=\"http://www.w3.org/1999/xhtml\">@import url(\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css\");</style><style>#mermaid-svg{font-family:\"trebuchet ms\",verdana,arial,sans-serif;font-size:16px;fill:#333;}#mermaid-svg .error-icon{fill:#552222;}#mermaid-svg .error-text{fill:#552222;stroke:#552222;}#mermaid-svg .edge-thickness-normal{stroke-width:2px;}#mermaid-svg .edge-thickness-thick{stroke-width:3.5px;}#mermaid-svg .edge-pattern-solid{stroke-dasharray:0;}#mermaid-svg .edge-pattern-dashed{stroke-dasharray:3;}#mermaid-svg .edge-pattern-dotted{stroke-dasharray:2;}#mermaid-svg .marker{fill:#333333;stroke:#333333;}#mermaid-svg .marker.cross{stroke:#333333;}#mermaid-svg svg{font-family:\"trebuchet ms\",verdana,arial,sans-serif;font-size:16px;}#mermaid-svg .label{font-family:\"trebuchet ms\",verdana,arial,sans-serif;color:#333;}#mermaid-svg .cluster-label text{fill:#333;}#mermaid-svg .cluster-label span,#mermaid-svg p{color:#333;}#mermaid-svg .label text,#mermaid-svg span,#mermaid-svg p{fill:#333;color:#333;}#mermaid-svg .node rect,#mermaid-svg .node circle,#mermaid-svg .node ellipse,#mermaid-svg .node polygon,#mermaid-svg .node path{fill:#ECECFF;stroke:#9370DB;stroke-width:1px;}#mermaid-svg .flowchart-label text{text-anchor:middle;}#mermaid-svg .node .katex path{fill:#000;stroke:#000;stroke-width:1px;}#mermaid-svg .node .label{text-align:center;}#mermaid-svg .node.clickable{cursor:pointer;}#mermaid-svg .arrowheadPath{fill:#333333;}#mermaid-svg .edgePath .path{stroke:#333333;stroke-width:2.0px;}#mermaid-svg .flowchart-link{stroke:#333333;fill:none;}#mermaid-svg .edgeLabel{background-color:#e8e8e8;text-align:center;}#mermaid-svg .edgeLabel rect{opacity:0.5;background-color:#e8e8e8;fill:#e8e8e8;}#mermaid-svg .labelBkg{background-color:rgba(232, 232, 232, 0.5);}#mermaid-svg .cluster rect{fill:#ffffde;stroke:#aaaa33;stroke-width:1px;}#mermaid-svg .cluster text{fill:#333;}#mermaid-svg .cluster span,#mermaid-svg p{color:#333;}#mermaid-svg div.mermaidTooltip{position:absolute;text-align:center;max-width:200px;padding:2px;font-family:\"trebuchet ms\",verdana,arial,sans-serif;font-size:12px;background:hsl(80, 100%, 96.2745098039%);border:1px solid #aaaa33;border-radius:2px;pointer-events:none;z-index:100;}#mermaid-svg .flowchartTitleText{text-anchor:middle;font-size:18px;fill:#333;}#mermaid-svg :root{--mermaid-font-family:\"trebuchet ms\",verdana,arial,sans-serif;}#mermaid-svg .stateNode&gt;*{fill:#fff!important;stroke:#333!important;stroke-width:2px!important;color:#000!important;}#mermaid-svg .stateNode span{fill:#fff!important;stroke:#333!important;stroke-width:2px!important;color:#000!important;}#mermaid-svg .stateNode tspan{fill:#000!important;}</style><g><marker id=\"mermaid-svg_flowchart-pointEnd\" class=\"marker flowchart\" viewBox=\"0 0 10 10\" refX=\"6\" refY=\"5\" markerUnits=\"userSpaceOnUse\" markerWidth=\"12\" markerHeight=\"12\" orient=\"auto\"><path d=\"M 0 0 L 10 5 L 0 10 z\" class=\"arrowMarkerPath\" style=\"stroke-width: 1; stroke-dasharray: 1, 0;\"/></marker><marker id=\"mermaid-svg_flowchart-pointStart\" class=\"marker flowchart\" viewBox=\"0 0 10 10\" refX=\"4.5\" refY=\"5\" markerUnits=\"userSpaceOnUse\" markerWidth=\"12\" markerHeight=\"12\" orient=\"auto\"><path d=\"M 0 5 L 10 10 L 10 0 z\" class=\"arrowMarkerPath\" style=\"stroke-width: 1; stroke-dasharray: 1, 0;\"/></marker><marker id=\"mermaid-svg_flowchart-circleEnd\" class=\"marker flowchart\" viewBox=\"0 0 10 10\" refX=\"11\" refY=\"5\" markerUnits=\"userSpaceOnUse\" markerWidth=\"11\" markerHeight=\"11\" orient=\"auto\"><circle cx=\"5\" cy=\"5\" r=\"5\" class=\"arrowMarkerPath\" style=\"stroke-width: 1; stroke-dasharray: 1, 0;\"/></marker><marker id=\"mermaid-svg_flowchart-circleStart\" class=\"marker flowchart\" viewBox=\"0 0 10 10\" refX=\"-1\" refY=\"5\" markerUnits=\"userSpaceOnUse\" markerWidth=\"11\" markerHeight=\"11\" orient=\"auto\"><circle cx=\"5\" cy=\"5\" r=\"5\" class=\"arrowMarkerPath\" style=\"stroke-width: 1; stroke-dasharray: 1, 0;\"/></marker><marker id=\"mermaid-svg_flowchart-crossEnd\" class=\"marker cross flowchart\" viewBox=\"0 0 11 11\" refX=\"12\" refY=\"5.2\" markerUnits=\"userSpaceOnUse\" markerWidth=\"11\" markerHeight=\"11\" orient=\"auto\"><path d=\"M 1,1 l 9,9 M 10,1 l -9,9\" class=\"arrowMarkerPath\" style=\"stroke-width: 2; stroke-dasharray: 1, 0;\"/></marker><marker id=\"mermaid-svg_flowchart-crossStart\" class=\"marker cross flowchart\" viewBox=\"0 0 11 11\" refX=\"-1\" refY=\"5.2\" markerUnits=\"userSpaceOnUse\" markerWidth=\"11\" markerHeight=\"11\" orient=\"auto\"><path d=\"M 1,1 l 9,9 M 10,1 l -9,9\" class=\"arrowMarkerPath\" style=\"stroke-width: 2; stroke-dasharray: 1, 0;\"/></marker><g class=\"root\"><g class=\"clusters\"/><g class=\"edgePaths\"><path d=\"M53.188,34L53.188,38.167C53.188,42.333,53.188,50.667,53.188,58.117C53.188,65.567,53.188,72.133,53.188,75.417L53.188,78.7\" id=\"L-goal-search-0\" class=\" edge-thickness-normal edge-pattern-solid flowchart-link LS-goal LE-search\" style=\"fill:none;\" marker-end=\"url(#mermaid-svg_flowchart-pointEnd)\"/><path d=\"M53.188,118L53.188,122.167C53.188,126.333,53.188,134.667,53.188,142.117C53.188,149.567,53.188,156.133,53.188,159.417L53.188,162.7\" id=\"L-search-search_filter-0\" class=\" edge-thickness-normal edge-pattern-solid flowchart-link LS-search LE-search_filter\" style=\"fill:none;\" marker-end=\"url(#mermaid-svg_flowchart-pointEnd)\"/><path d=\"M53.188,202L53.188,206.167C53.188,210.333,53.188,218.667,53.188,226.117C53.188,233.567,53.188,240.133,53.188,243.417L53.188,246.7\" id=\"L-search_filter-final_answer-0\" class=\" edge-thickness-normal edge-pattern-solid flowchart-link LS-search_filter LE-final_answer\" style=\"fill:none;\" marker-end=\"url(#mermaid-svg_flowchart-pointEnd)\"/><path d=\"M53.188,286L53.188,290.167C53.188,294.333,53.188,302.667,53.188,310.117C53.188,317.567,53.188,324.133,53.188,327.417L53.188,330.7\" id=\"L-final_answer-exit-0\" class=\" edge-thickness-normal edge-pattern-solid flowchart-link LS-final_answer LE-exit\" style=\"fill:none;\" marker-end=\"url(#mermaid-svg_flowchart-pointEnd)\"/></g><g class=\"edgeLabels\"><g class=\"edgeLabel\"><g class=\"label\" transform=\"translate(0, 0)\"><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"edgeLabel\"></span></div></foreignObject></g></g><g class=\"edgeLabel\"><g class=\"label\" transform=\"translate(0, 0)\"><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"edgeLabel\"></span></div></foreignObject></g></g><g class=\"edgeLabel\"><g class=\"label\" transform=\"translate(0, 0)\"><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"edgeLabel\"></span></div></foreignObject></g></g><g class=\"edgeLabel\"><g class=\"label\" transform=\"translate(0, 0)\"><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"edgeLabel\"></span></div></foreignObject></g></g></g><g class=\"nodes\"><g class=\"node default default flowchart-label\" id=\"flowchart-goal-0\" data-node=\"true\" data-id=\"goal\" transform=\"translate(53.1875, 17)\"><rect class=\"basic label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-22.375\" y=\"-17\" width=\"44.75\" height=\"34\"/><g class=\"label\" style=\"\" transform=\"translate(-14.875, -9.5)\"><rect/><foreignObject width=\"29.75\" height=\"19\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">goal</span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"flowchart-search-1\" data-node=\"true\" data-id=\"search\" transform=\"translate(53.1875, 101)\"><rect class=\"basic label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-30.75\" y=\"-17\" width=\"61.5\" height=\"34\"/><g class=\"label\" style=\"\" transform=\"translate(-23.25, -9.5)\"><rect/><foreignObject width=\"46.5\" height=\"19\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">search</span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"flowchart-search_filter-3\" data-node=\"true\" data-id=\"search_filter\" transform=\"translate(53.1875, 185)\"><rect class=\"basic label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-53.1875\" y=\"-17\" width=\"106.375\" height=\"34\"/><g class=\"label\" style=\"\" transform=\"translate(-45.6875, -9.5)\"><rect/><foreignObject width=\"91.375\" height=\"19\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">search_filter</span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"flowchart-final_answer-5\" data-node=\"true\" data-id=\"final_answer\" transform=\"translate(53.1875, 269)\"><rect class=\"basic label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-53.109375\" y=\"-17\" width=\"106.21875\" height=\"34\"/><g class=\"label\" style=\"\" transform=\"translate(-45.609375, -9.5)\"><rect/><foreignObject width=\"91.21875\" height=\"19\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">final_answer</span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"flowchart-exit-7\" data-node=\"true\" data-id=\"exit\" transform=\"translate(53.1875, 353)\"><rect class=\"basic label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-21.328125\" y=\"-17\" width=\"42.65625\" height=\"34\"/><g class=\"label\" style=\"\" transform=\"translate(-13.828125, -9.5)\"><rect/><foreignObject width=\"27.65625\" height=\"19\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">exit</span></div></foreignObject></g></g></g></g></g></svg>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mermaid as md\n",
    "from mermaid.graph import Graph\n",
    "\n",
    "graph: Graph = Graph('example', \"\"\"\n",
    "graph TD;\n",
    "    goal --> search\n",
    "    search --> search_filter\n",
    "    search_filter --> final_answer\n",
    "    final_answer --> exit\n",
    "\n",
    "    classDef stateNode fill:#fff,stroke:#333,stroke-width:2px,color:#000;\n",
    "\"\"\")\n",
    "graphe: md.Mermaid = md.Mermaid(graph)\n",
    "graphe"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-05T18:48:06.512673600Z",
     "start_time": "2024-05-05T18:48:04.869954400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-05T18:48:06.514672600Z",
     "start_time": "2024-05-05T18:48:06.512673600Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
