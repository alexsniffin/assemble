{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Tool Agent"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (0.0.36)\n",
      "Requirement already satisfied: wikipedia in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (1.4.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from langchain-community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from langchain-community) (2.0.29)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from langchain-community) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from langchain-community) (0.6.5)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.48 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from langchain-community) (0.1.50)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from langchain-community) (0.1.54)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from langchain-community) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from langchain-community) (8.2.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from wikipedia) (4.12.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.48->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.48->langchain-community) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.48->langchain-community) (2.7.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from requests<3,>=2->langchain-community) (2024.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (4.11.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from beautifulsoup4->wikipedia) (2.5)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.48->langchain-community) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.48->langchain-community) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.48->langchain-community) (2.18.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv langchain-community wikipedia"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-05T05:31:13.402655900Z",
     "start_time": "2024-05-05T05:31:12.256791200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "model_path = os.getenv(\"MODEL_PATH\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-05T05:33:13.206847300Z",
     "start_time": "2024-05-05T05:33:13.187332200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 23 key-value pairs and 291 tensors from D:\\llm-models\\NousResearch\\Hermes-2-Pro-Llama-3-8B-GGUF\\Hermes-2-Pro-Llama-3-8B-Q8_0.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = Hermes-2-Pro-Llama-3-8B\n",
      "llama_model_loader: - kv   2:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   3:                       llama.context_length u32              = 8192\n",
      "llama_model_loader: - kv   4:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   7:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   8:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 7\n",
      "llama_model_loader: - kv  11:                           llama.vocab_size u32              = 128288\n",
      "llama_model_loader: - kv  12:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  13:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  14:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  15:                      tokenizer.ggml.tokens arr[str,128288]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  16:                  tokenizer.ggml.token_type arr[i32,128288]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  17:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  18:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  19:                tokenizer.ggml.eos_token_id u32              = 128003\n",
      "llama_model_loader: - kv  20:            tokenizer.ggml.padding_token_id u32              = 128001\n",
      "llama_model_loader: - kv  21:                    tokenizer.chat_template str              = {{bos_token}}{% for message in messag...\n",
      "llama_model_loader: - kv  22:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q8_0:  226 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 288/128288 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = BPE\n",
      "llm_load_print_meta: n_vocab          = 128288\n",
      "llm_load_print_meta: n_merges         = 280147\n",
      "llm_load_print_meta: n_ctx_train      = 8192\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 500000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 8192\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 8B\n",
      "llm_load_print_meta: model ftype      = Q8_0\n",
      "llm_load_print_meta: model params     = 8.03 B\n",
      "llm_load_print_meta: model size       = 7.95 GiB (8.50 BPW) \n",
      "llm_load_print_meta: general.name     = Hermes-2-Pro-Llama-3-8B\n",
      "llm_load_print_meta: BOS token        = 128000 '<|begin_of_text|>'\n",
      "llm_load_print_meta: EOS token        = 128003 '<|im_end|>'\n",
      "llm_load_print_meta: PAD token        = 128001 '<|end_of_text|>'\n",
      "llm_load_print_meta: LF token         = 128 'Ä'\n",
      "llm_load_print_meta: EOT token        = 128003 '<|im_end|>'\n",
      "llm_load_tensors: ggml ctx size =    0.30 MiB\n",
      "llm_load_tensors: offloading 32 repeating layers to GPU\n",
      "llm_load_tensors: offloading non-repeating layers to GPU\n",
      "llm_load_tensors: offloaded 33/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =   532.45 MiB\n",
      "llm_load_tensors:      CUDA0 buffer size =  7605.46 MiB\n",
      ".........................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 8192\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 500000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:      CUDA0 KV buffer size =  1024.00 MiB\n",
      "llama_new_context_with_model: KV self size  = 1024.00 MiB, K (f16):  512.00 MiB, V (f16):  512.00 MiB\n",
      "llama_new_context_with_model:  CUDA_Host  output buffer size =     0.49 MiB\n",
      "llama_new_context_with_model:      CUDA0 compute buffer size =   560.00 MiB\n",
      "llama_new_context_with_model:  CUDA_Host compute buffer size =    24.01 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 2\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'general.name': 'Hermes-2-Pro-Llama-3-8B', 'general.architecture': 'llama', 'llama.block_count': '32', 'llama.context_length': '8192', 'tokenizer.ggml.eos_token_id': '128003', 'general.file_type': '7', 'llama.attention.head_count_kv': '8', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.head_count': '32', 'llama.rope.freq_base': '500000.000000', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.vocab_size': '128288', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.model': 'gpt2', 'tokenizer.ggml.pre': 'llama-bpe', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '128000', 'tokenizer.ggml.padding_token_id': '128001', 'tokenizer.chat_template': \"{{bos_token}}{% for message in messages %}{{'<|im_start|>' + message['role'] + '\\n' + message['content'] + '<|im_end|>' + '\\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\\n' }}{% endif %}\"}\n",
      "Using gguf chat template: {{bos_token}}{% for message in messages %}{{'<|im_start|>' + message['role'] + '\n",
      "' + message['content'] + '<|im_end|>' + '\n",
      "'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n",
      "' }}{% endif %}\n",
      "Using chat eos_token: <|im_end|>\n",
      "Using chat bos_token: <|begin_of_text|>\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "from app.llm.generator import Generator\n",
    "from app.llm.llamacpp.service import LlamaCppService\n",
    "from app.state.final_answer.factory import FinalAnswerFactory\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "llm = LlamaCppService(model_path=model_path, n_gpu_layers=-1)\n",
    "\n",
    "final_answer_state = FinalAnswerFactory.get_node(Generator(\n",
    "    service=llm,\n",
    "    temperature=0.4,\n",
    "))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-05T05:33:18.678010600Z",
     "start_time": "2024-05-05T05:33:15.225146200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from pykka import ActorRef\n",
    "from app.tools.adapter import ToolAdapter\n",
    "from app.agent import BaseAgent\n",
    "from app.state.node import Node, GenerationHandlerResponse\n",
    "from app.memory.memory import Memory\n",
    "from app.persona.persona import Persona\n",
    "from app.llm.generator import Generator\n",
    "from app.tools.langchain.wikipedia_query_run import LangchainWikipediaQueryRun\n",
    "from typing import Dict, Any, Optional, List\n",
    "\n",
    "tools = [LangchainWikipediaQueryRun(top_k_results=2, doc_content_chars_max=2048)]\n",
    "\n",
    "\n",
    "class DelegationAgent(BaseAgent):\n",
    "    def __init__(self, workers: List[ActorRef], persona: Persona, memory: Memory, nodes: List[Node],\n",
    "                 default_initial_state: str, step_limit: int):\n",
    "        super().__init__(persona, memory, nodes, default_initial_state, step_limit)\n",
    "        memory.data.set(\"workers\", workers)\n",
    "\n",
    "\n",
    "def delegate_prompt_handler(persona: Persona, memory: Memory, _: Optional[Dict[str, Any]]) -> str:\n",
    "    proxy_workers = [worker.proxy() for worker in memory.data.get(\"workers\")]\n",
    "    workers = [f\"{worker.name.get()}: {worker.description.get()}\" for worker in proxy_workers]\n",
    "    return f'''{persona.prompt()}\n",
    "\n",
    "Given the problem, determine which of your workers can help solve the problem and let them do it.\n",
    "\n",
    "If none of your workers can help solve the problem, respond with \"NONE: \" and give the reason after.\n",
    "\n",
    "Current Problem:\n",
    "\"\"\"\n",
    "{memory.data.get_current_message().content}\n",
    "\"\"\"\n",
    "\n",
    "Workers:\n",
    "\"\"\"\n",
    "{workers}\n",
    "\"\"\"\n",
    "\n",
    "Respond with only the name of the worker that can help solve the problem.'''\n",
    "\n",
    "\n",
    "def delegate_generation_handler(\n",
    "        response: str,\n",
    "        memory: Memory,\n",
    "        _: Optional[List[ToolAdapter]]) -> GenerationHandlerResponse:\n",
    "    if \"NONE: \" in response:\n",
    "        print(f\"response: {response}\")\n",
    "        parse_response = response.split(\"NONE: \")[1].strip()\n",
    "        return GenerationHandlerResponse(\n",
    "            output=parse_response,\n",
    "            next_state=final_answer_state.state_name,\n",
    "            exclude_from_scratch_pad=True\n",
    "        )\n",
    "\n",
    "    worker = next((worker for worker in memory.data.get(\"workers\") if worker.proxy().name.get() == response), None)\n",
    "    if worker is not None:\n",
    "        future = worker.ask(Query(goal=memory.data.get_current_message().content, delete_scratch_pad_on_finish=True))\n",
    "        result = future.get()\n",
    "\n",
    "        if result is not None:\n",
    "            return GenerationHandlerResponse(\n",
    "                output=f\"Delegated to: {response}\\nOutput: {result.output}\",\n",
    "                next_state=final_answer_state.state_name,\n",
    "                exclude_from_scratch_pad=False\n",
    "            )\n",
    "        else:\n",
    "            return GenerationHandlerResponse(\n",
    "                output=\"Failed to get a response from the worker.\",\n",
    "                next_state=final_answer_state.state_name,\n",
    "                exclude_from_scratch_pad=True\n",
    "            )\n",
    "    return GenerationHandlerResponse(\n",
    "        output=\"No worker found with that name.\",\n",
    "        next_state=final_answer_state.state_name,\n",
    "        exclude_from_scratch_pad=True\n",
    "    )\n",
    "\n",
    "\n",
    "delegate_node = Node(\n",
    "    state_name=\"delegate\",\n",
    "    prompt_handler=delegate_prompt_handler,\n",
    "    generation_handler=delegate_generation_handler,\n",
    "    generator=Generator(\n",
    "        service=llm,\n",
    "        temperature=0.1,\n",
    "    ),\n",
    "    tools=tools,\n",
    ")\n",
    "\n",
    "delegation_persona = Persona(\n",
    "    description=\"You're an a helpful assistant. Help the user solve their problem.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-05T05:33:28.248843400Z",
     "start_time": "2024-05-05T05:33:27.972575Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from app.tools.langchain.yahoo_finance_news import LangchainYahooFinanceNews\n",
    "from app.state.defaults import default_tools_handler\n",
    "from app.state.node import Node\n",
    "from app.memory.memory import Memory\n",
    "from app.persona.persona import Persona\n",
    "from app.llm.generator import Generator\n",
    "from app.tools.langchain.wikipedia_query_run import LangchainWikipediaQueryRun\n",
    "from typing import Dict, Any, Optional\n",
    "\n",
    "tools = [\n",
    "    LangchainWikipediaQueryRun(top_k_results=2, doc_content_chars_max=2048),\n",
    "    LangchainYahooFinanceNews(top_k=2)\n",
    "]\n",
    "\n",
    "\n",
    "class SearchAgent(BaseAgent):\n",
    "    name = \"SearchAgent\"\n",
    "    description = \"Specializes in searching for information.\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def search_prompt_handler(persona: Persona, memory: Memory, tool_schemas: Optional[Dict[str, Any]]) -> str:\n",
    "    messages_formatted = [f\"{message.name}: {message.content}\\n\" for message in memory.data.get_all_messages()]\n",
    "    return f'''{persona.prompt()}\n",
    "\n",
    "Search for information using your tools to help solve the following problem for the user. Use any previous messages as context.\n",
    "\n",
    "Current Problem:\n",
    "\"\"\"\n",
    "{memory.data.get_current_message().content}\n",
    "\"\"\"\n",
    "\n",
    "Previous Messages:\n",
    "\"\"\"\n",
    "{messages_formatted}\n",
    "\"\"\"\n",
    "\n",
    "Here are the schemas for the tools you have access to, pick only one:\n",
    "\"\"\"\n",
    "{tool_schemas}\n",
    "\"\"\"\n",
    "\n",
    "Respond with the JSON input for the tool of your choice to best solve the problem.'''\n",
    "\n",
    "\n",
    "search_node = Node(\n",
    "    state_name=\"search\",\n",
    "    prompt_handler=search_prompt_handler,\n",
    "    generation_handler=default_tools_handler(\n",
    "        next_state=final_answer_state.state_name,\n",
    "        exclude_from_scratch_pad=False\n",
    "    ),\n",
    "    generator=Generator(\n",
    "        service=llm,\n",
    "        use_json_model=True,\n",
    "        temperature=0.1,\n",
    "    ),\n",
    "    tools=tools,\n",
    ")\n",
    "\n",
    "search_persona = Persona(description=\"You're an expert researcher.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-05T05:33:29.470309600Z",
     "start_time": "2024-05-05T05:33:29.168580300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-05T05:33:33.689449Z",
     "start_time": "2024-05-05T05:33:33.684059700Z"
    }
   },
   "outputs": [],
   "source": [
    "search_agent = SearchAgent.start(persona=search_persona, memory=Memory(), nodes=[search_node, final_answer_state],\n",
    "                                 default_initial_state=\"search\", step_limit=5)\n",
    "delegate_agent = DelegationAgent.start(persona=delegation_persona, memory=Memory(),\n",
    "                                       nodes=[delegate_node, final_answer_state], workers=[search_agent],\n",
    "                                       default_initial_state=\"delegate\", step_limit=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "Timeout",
     "evalue": "120 seconds",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTimeout\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m future \u001B[38;5;241m=\u001B[39m delegate_agent\u001B[38;5;241m.\u001B[39mask(Query(initial_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdelegate\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m      2\u001B[0m                                   goal\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFind the latest news on NVDA stock.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m      3\u001B[0m                                   delete_scratch_pad_on_finish\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m))\n\u001B[1;32m----> 4\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[43mfuture\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m120\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(json\u001B[38;5;241m.\u001B[39mdumps([step\u001B[38;5;241m.\u001B[39mmodel_dump() \u001B[38;5;28;01mfor\u001B[39;00m step \u001B[38;5;129;01min\u001B[39;00m response\u001B[38;5;241m.\u001B[39msteps], indent\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m))\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(response\u001B[38;5;241m.\u001B[39moutput)\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\assemble-qevGTaVi-py3.11\\Lib\\site-packages\\pykka\\_threading.py:70\u001B[0m, in \u001B[0;36mThreadingFuture.get\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m     68\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m exc_value\n\u001B[0;32m     69\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m queue\u001B[38;5;241m.\u001B[39mEmpty:\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Timeout(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtimeout\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m seconds\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_result\u001B[38;5;241m.\u001B[39mvalue\n",
      "\u001B[1;31mTimeout\u001B[0m: 120 seconds"
     ]
    }
   ],
   "source": [
    "from app.agent.messages import Query\n",
    "\n",
    "future = delegate_agent.ask(Query(initial_state=\"delegate\",\n",
    "                                  goal=\"Find the latest news on NVDA stock.\"))\n",
    "response = future.get(timeout=120)\n",
    "print(json.dumps([step.model_dump() for step in response.steps], indent=2))\n",
    "print(response.output)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"name\": \"delegate\",\n",
      "    \"prompt\": \"You're an a helpful assistant. Help the user solve their problem.\\n\\nGiven the problem, determine which of your workers can help solve the problem and let them do it.\\n\\nIf none of your workers can help solve the problem, respond with \\\"NONE: \\\" and give the reason after.\\n\\nCurrent Problem:\\n\\\"\\\"\\\"\\nCan you research anything mentioned about it? Give me a summery.\\n\\\"\\\"\\\"\\n\\nWorkers:\\n\\\"\\\"\\\"\\n['SearchAgent: Specializes in searching for information.']\\n\\\"\\\"\\\"\\n\\nRespond with only the name of the worker that can help solve the problem.\",\n",
      "    \"output\": \"Delegated to: SearchAgent\\nOutput: The user requested information about \\\"NVDA stock\\\". After conducting research using the Wikipedia query tool, we found two relevant pages: ServiceNow and the Russell 3000 Index.\\n\\nServiceNow, Inc., the company behind NVDA (New Video Distribution Architecture) stock, is an American software company that develops a cloud computing platform to help manage digital workflows for enterprise operations. The company was founded in 2003 by Fred Luddy and is listed on the New York Stock Exchange as part of both the Russell 1000 Index and S&P 500 Index. In 2018, Forbes named ServiceNow as the most innovative company in the world.\\n\\nThe Russell 3000 Index is a stock market index that serves as a benchmark for the entire U.S. stock market. It includes the 3,000 largest publicly held companies incorporated in America based on total market capitalization and represents approximately 97% of the American public equity market. The index was launched in 1984 and is maintained by FTSE Russell, a subsidiary of the London Stock Exchange Group. The ticker symbol for the Russell 3000 Index is ^RUA.\\n\\nIn summary, NVDA stock refers to the stock of ServiceNow, Inc., an innovative software company that develops cloud computing platforms for enterprise operations. It is listed on the New York Stock Exchange and is part of the Russell 3000 Index, which represents a significant portion of the U.S. stock market.\",\n",
      "    \"next\": \"final_answer\",\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 2,\n",
      "      \"prompt_tokens\": 117,\n",
      "      \"total_tokens\": 119\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"final_answer\",\n",
      "    \"prompt\": \"You're an a helpful assistant. Help the user solve their problem.\\n\\nGiven the problem from the user and your notes, provide an answer using what you know.\\n\\nProblem:\\n\\\"\\\"\\\"\\nCan you research anything mentioned about it? Give me a summery.\\n\\\"\\\"\\\"\\n\\nNotes:\\n\\\"\\\"\\\"\\n\\ndelegate: Delegated to: SearchAgent\\nOutput: The user requested information about \\\"NVDA stock\\\". After conducting research using the Wikipedia query tool, we found two relevant pages: ServiceNow and the Russell 3000 Index.\\n\\nServiceNow, Inc., the company behind NVDA (New Video Distribution Architecture) stock, is an American software company that develops a cloud computing platform to help manage digital workflows for enterprise operations. The company was founded in 2003 by Fred Luddy and is listed on the New York Stock Exchange as part of both the Russell 1000 Index and S&P 500 Index. In 2018, Forbes named ServiceNow as the most innovative company in the world.\\n\\nThe Russell 3000 Index is a stock market index that serves as a benchmark for the entire U.S. stock market. It includes the 3,000 largest publicly held companies incorporated in America based on total market capitalization and represents approximately 97% of the American public equity market. The index was launched in 1984 and is maintained by FTSE Russell, a subsidiary of the London Stock Exchange Group. The ticker symbol for the Russell 3000 Index is ^RUA.\\n\\nIn summary, NVDA stock refers to the stock of ServiceNow, Inc., an innovative software company that develops cloud computing platforms for enterprise operations. It is listed on the New York Stock Exchange and is part of the Russell 3000 Index, which represents a significant portion of the U.S. stock market.\\n\\\"\\\"\\\"\\n\\nYour answer.\",\n",
      "    \"output\": \"Based on my research, NVDA stock refers to the stock of ServiceNow, Inc., an American software company that develops cloud computing platforms for enterprise operations. Founded in 2003 by Fred Luddy and listed on the New York Stock Exchange, ServiceNow is part of both the Russell 1000 Index and S&P 500 Index. The Russell 3000 Index serves as a benchmark for the entire U.S. stock market, including approximately 97% of the American public equity market. In summary, NVDA stock represents an important player in the technology industry with significant presence in the U.S. stock market.\",\n",
      "    \"next\": \"exit\",\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 124,\n",
      "      \"prompt_tokens\": 368,\n",
      "      \"total_tokens\": 492\n",
      "    }\n",
      "  }\n",
      "]\n",
      "Based on my research, NVDA stock refers to the stock of ServiceNow, Inc., an American software company that develops cloud computing platforms for enterprise operations. Founded in 2003 by Fred Luddy and listed on the New York Stock Exchange, ServiceNow is part of both the Russell 1000 Index and S&P 500 Index. The Russell 3000 Index serves as a benchmark for the entire U.S. stock market, including approximately 97% of the American public equity market. In summary, NVDA stock represents an important player in the technology industry with significant presence in the U.S. stock market.\n"
     ]
    }
   ],
   "source": [
    "future = delegate_agent.ask(Query(initial_state=\"delegate\",\n",
    "                                  goal=\"Can you research anything mentioned about it? Give me a summery.\"))\n",
    "response = future.get(timeout=120)\n",
    "print(json.dumps([step.model_dump() for step in response.steps], indent=2))\n",
    "print(response.output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-05T05:31:42.623399800Z",
     "start_time": "2024-05-05T05:31:28.228858700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_agent.stop()\n",
    "delegate_agent.stop()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-05T05:31:42.628399200Z",
     "start_time": "2024-05-05T05:31:42.624222600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mermaid-py in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (0.5.0)\n",
      "Requirement already satisfied: ipython<9.0.0,>=8.17.2 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from mermaid-py) (8.24.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from mermaid-py) (2.31.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from ipython<9.0.0,>=8.17.2->mermaid-py) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from ipython<9.0.0,>=8.17.2->mermaid-py) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from ipython<9.0.0,>=8.17.2->mermaid-py) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from ipython<9.0.0,>=8.17.2->mermaid-py) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from ipython<9.0.0,>=8.17.2->mermaid-py) (2.18.0)\n",
      "Requirement already satisfied: stack-data in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from ipython<9.0.0,>=8.17.2->mermaid-py) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from ipython<9.0.0,>=8.17.2->mermaid-py) (5.14.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from ipython<9.0.0,>=8.17.2->mermaid-py) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from ipython<9.0.0,>=8.17.2->mermaid-py) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from requests<3.0.0,>=2.31.0->mermaid-py) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from requests<3.0.0,>=2.31.0->mermaid-py) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from requests<3.0.0,>=2.31.0->mermaid-py) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from requests<3.0.0,>=2.31.0->mermaid-py) (2024.2.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from jedi>=0.16->ipython<9.0.0,>=8.17.2->mermaid-py) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython<9.0.0,>=8.17.2->mermaid-py) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from stack-data->ipython<9.0.0,>=8.17.2->mermaid-py) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from stack-data->ipython<9.0.0,>=8.17.2->mermaid-py) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from stack-data->ipython<9.0.0,>=8.17.2->mermaid-py) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\alexander\\appdata\\local\\pypoetry\\cache\\virtualenvs\\assemble-qevgtavi-py3.11\\lib\\site-packages (from asttokens>=2.1.0->stack-data->ipython<9.0.0,>=8.17.2->mermaid-py) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install mermaid-py"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-05T05:31:43.689315900Z",
     "start_time": "2024-05-05T05:31:42.628399200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "<mermaid._main.Mermaid at 0x2593f29ad0>",
      "text/html": "<svg id=\"mermaid-svg\" width=\"100%\" xmlns=\"http://www.w3.org/2000/svg\" style=\"max-width: 391.421875px;\" viewBox=\"-8 -8 391.421875 589\" role=\"graphics-document document\" aria-roledescription=\"flowchart-v2\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><style xmlns=\"http://www.w3.org/1999/xhtml\">@import url(\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css\");</style><style>#mermaid-svg{font-family:\"trebuchet ms\",verdana,arial,sans-serif;font-size:16px;fill:#333;}#mermaid-svg .error-icon{fill:#552222;}#mermaid-svg .error-text{fill:#552222;stroke:#552222;}#mermaid-svg .edge-thickness-normal{stroke-width:2px;}#mermaid-svg .edge-thickness-thick{stroke-width:3.5px;}#mermaid-svg .edge-pattern-solid{stroke-dasharray:0;}#mermaid-svg .edge-pattern-dashed{stroke-dasharray:3;}#mermaid-svg .edge-pattern-dotted{stroke-dasharray:2;}#mermaid-svg .marker{fill:#333333;stroke:#333333;}#mermaid-svg .marker.cross{stroke:#333333;}#mermaid-svg svg{font-family:\"trebuchet ms\",verdana,arial,sans-serif;font-size:16px;}#mermaid-svg .label{font-family:\"trebuchet ms\",verdana,arial,sans-serif;color:#333;}#mermaid-svg .cluster-label text{fill:#333;}#mermaid-svg .cluster-label span,#mermaid-svg p{color:#333;}#mermaid-svg .label text,#mermaid-svg span,#mermaid-svg p{fill:#333;color:#333;}#mermaid-svg .node rect,#mermaid-svg .node circle,#mermaid-svg .node ellipse,#mermaid-svg .node polygon,#mermaid-svg .node path{fill:#ECECFF;stroke:#9370DB;stroke-width:1px;}#mermaid-svg .flowchart-label text{text-anchor:middle;}#mermaid-svg .node .katex path{fill:#000;stroke:#000;stroke-width:1px;}#mermaid-svg .node .label{text-align:center;}#mermaid-svg .node.clickable{cursor:pointer;}#mermaid-svg .arrowheadPath{fill:#333333;}#mermaid-svg .edgePath .path{stroke:#333333;stroke-width:2.0px;}#mermaid-svg .flowchart-link{stroke:#333333;fill:none;}#mermaid-svg .edgeLabel{background-color:#e8e8e8;text-align:center;}#mermaid-svg .edgeLabel rect{opacity:0.5;background-color:#e8e8e8;fill:#e8e8e8;}#mermaid-svg .labelBkg{background-color:rgba(232, 232, 232, 0.5);}#mermaid-svg .cluster rect{fill:#ffffde;stroke:#aaaa33;stroke-width:1px;}#mermaid-svg .cluster text{fill:#333;}#mermaid-svg .cluster span,#mermaid-svg p{color:#333;}#mermaid-svg div.mermaidTooltip{position:absolute;text-align:center;max-width:200px;padding:2px;font-family:\"trebuchet ms\",verdana,arial,sans-serif;font-size:12px;background:hsl(80, 100%, 96.2745098039%);border:1px solid #aaaa33;border-radius:2px;pointer-events:none;z-index:100;}#mermaid-svg .flowchartTitleText{text-anchor:middle;font-size:18px;fill:#333;}#mermaid-svg :root{--mermaid-font-family:\"trebuchet ms\",verdana,arial,sans-serif;}#mermaid-svg .agent&gt;*{fill:#f9f!important;stroke:#333!important;stroke-width:2px!important;}#mermaid-svg .agent span{fill:#f9f!important;stroke:#333!important;stroke-width:2px!important;}</style><g><marker id=\"mermaid-svg_flowchart-pointEnd\" class=\"marker flowchart\" viewBox=\"0 0 10 10\" refX=\"6\" refY=\"5\" markerUnits=\"userSpaceOnUse\" markerWidth=\"12\" markerHeight=\"12\" orient=\"auto\"><path d=\"M 0 0 L 10 5 L 0 10 z\" class=\"arrowMarkerPath\" style=\"stroke-width: 1; stroke-dasharray: 1, 0;\"/></marker><marker id=\"mermaid-svg_flowchart-pointStart\" class=\"marker flowchart\" viewBox=\"0 0 10 10\" refX=\"4.5\" refY=\"5\" markerUnits=\"userSpaceOnUse\" markerWidth=\"12\" markerHeight=\"12\" orient=\"auto\"><path d=\"M 0 5 L 10 10 L 10 0 z\" class=\"arrowMarkerPath\" style=\"stroke-width: 1; stroke-dasharray: 1, 0;\"/></marker><marker id=\"mermaid-svg_flowchart-circleEnd\" class=\"marker flowchart\" viewBox=\"0 0 10 10\" refX=\"11\" refY=\"5\" markerUnits=\"userSpaceOnUse\" markerWidth=\"11\" markerHeight=\"11\" orient=\"auto\"><circle cx=\"5\" cy=\"5\" r=\"5\" class=\"arrowMarkerPath\" style=\"stroke-width: 1; stroke-dasharray: 1, 0;\"/></marker><marker id=\"mermaid-svg_flowchart-circleStart\" class=\"marker flowchart\" viewBox=\"0 0 10 10\" refX=\"-1\" refY=\"5\" markerUnits=\"userSpaceOnUse\" markerWidth=\"11\" markerHeight=\"11\" orient=\"auto\"><circle cx=\"5\" cy=\"5\" r=\"5\" class=\"arrowMarkerPath\" style=\"stroke-width: 1; stroke-dasharray: 1, 0;\"/></marker><marker id=\"mermaid-svg_flowchart-crossEnd\" class=\"marker cross flowchart\" viewBox=\"0 0 11 11\" refX=\"12\" refY=\"5.2\" markerUnits=\"userSpaceOnUse\" markerWidth=\"11\" markerHeight=\"11\" orient=\"auto\"><path d=\"M 1,1 l 9,9 M 10,1 l -9,9\" class=\"arrowMarkerPath\" style=\"stroke-width: 2; stroke-dasharray: 1, 0;\"/></marker><marker id=\"mermaid-svg_flowchart-crossStart\" class=\"marker cross flowchart\" viewBox=\"0 0 11 11\" refX=\"-1\" refY=\"5.2\" markerUnits=\"userSpaceOnUse\" markerWidth=\"11\" markerHeight=\"11\" orient=\"auto\"><path d=\"M 1,1 l 9,9 M 10,1 l -9,9\" class=\"arrowMarkerPath\" style=\"stroke-width: 2; stroke-dasharray: 1, 0;\"/></marker><g class=\"root\"><g class=\"clusters\"><g class=\"cluster agent agent flowchart-label\" id=\"DA\"><rect style=\"\" rx=\"0\" ry=\"0\" x=\"0\" y=\"321\" width=\"375.421875\" height=\"252\"/><g class=\"cluster-label\" transform=\"translate(126.7734375, 321)\"><foreignObject width=\"121.875\" height=\"19\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">Delegation Agent</span></div></foreignObject></g></g></g><g class=\"edgePaths\"><path d=\"M111.031,380L111.031,384.167C111.031,388.333,111.031,396.667,115.587,404.527C120.142,412.387,129.253,419.775,133.809,423.468L138.364,427.162\" id=\"L-DA_Start-DA_DelegateNode-0\" class=\" edge-thickness-normal edge-pattern-solid flowchart-link LS-DA_Start LE-DA_DelegateNode\" style=\"fill:none;\" marker-end=\"url(#mermaid-svg_flowchart-pointEnd)\"/><path d=\"M163.527,464.5L163.444,468.583C163.361,472.667,163.194,480.833,163.111,488.2C163.027,495.567,163.027,502.133,163.027,505.417L163.027,508.7\" id=\"L-DA_DelegateNode-DA_FinalState-0\" class=\" edge-thickness-normal edge-pattern-solid flowchart-link LS-DA_DelegateNode LE-DA_FinalState\" style=\"fill:none;\" marker-end=\"url(#mermaid-svg_flowchart-pointEnd)\"/><path d=\"M72.188,143.5L72.104,167.333C72.021,191.167,71.854,238.833,71.771,268.417C71.688,298,71.688,309.5,74.987,318.772C78.286,328.044,84.885,335.088,88.184,338.61L91.483,342.132\" id=\"L-QueryNode-DA_Start-0\" class=\" edge-thickness-normal edge-pattern-solid flowchart-link LS-QueryNode LE-DA_Start\" style=\"fill:none;\" marker-end=\"url(#mermaid-svg_flowchart-pointEnd)\"/><path d=\"M215.923,430L228.888,425.833C241.852,421.667,267.782,413.333,280.746,402.167C293.711,391,293.711,377,293.711,363C293.711,349,293.711,335,293.711,322.25C293.711,309.5,293.711,298,292.512,287.358C291.313,276.716,288.914,266.932,287.715,262.04L286.516,257.148\" id=\"L-DA_DelegateNode-SA-0\" class=\" edge-thickness-normal edge-pattern-dotted flowchart-link LS-DA_DelegateNode LE-SA\" style=\"fill:none;stroke-width:2px;stroke-dasharray:3;\" marker-end=\"url(#mermaid-svg_flowchart-pointEnd)\"/><path d=\"M213.548,252L211.685,257.75C209.822,263.5,206.097,275,204.234,285.617C202.371,296.233,202.371,305.967,202.371,310.833L202.371,315.7\" id=\"L-SA-DA-0\" class=\" edge-thickness-normal edge-pattern-dotted flowchart-link LS-SA LE-DA\" style=\"fill:none;stroke-width:2px;stroke-dasharray:3;\" marker-end=\"url(#mermaid-svg_flowchart-pointEnd)\"/></g><g class=\"edgeLabels\"><g class=\"edgeLabel\"><g class=\"label\" transform=\"translate(0, 0)\"><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"edgeLabel\"></span></div></foreignObject></g></g><g class=\"edgeLabel\"><g class=\"label\" transform=\"translate(0, 0)\"><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"edgeLabel\"></span></div></foreignObject></g></g><g class=\"edgeLabel\"><g class=\"label\" transform=\"translate(0, 0)\"><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"edgeLabel\"></span></div></foreignObject></g></g><g class=\"edgeLabel\" transform=\"translate(293.7109375, 363)\"><g class=\"label\" transform=\"translate(-40.046875, -9.5)\"><foreignObject width=\"80.09375\" height=\"19\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"edgeLabel\">Ask/Search</span></div></foreignObject></g></g><g class=\"edgeLabel\" transform=\"translate(202.64312, 285.66033)\"><g class=\"label\" transform=\"translate(-58.6875, -9.5)\"><foreignObject width=\"117.375\" height=\"19\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"edgeLabel\">Response/Result</span></div></foreignObject></g></g></g><g class=\"nodes\"><g class=\"root\" transform=\"translate(151.3828125, -8)\"><g class=\"clusters\"><g class=\"cluster agent agent flowchart-label\" id=\"SA\"><rect style=\"\" rx=\"0\" ry=\"0\" x=\"8\" y=\"8\" width=\"190.96875\" height=\"252\"/><g class=\"cluster-label\" transform=\"translate(57.015625, 8)\"><foreignObject width=\"92.9375\" height=\"19\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">Search Agent</span></div></foreignObject></g></g></g><g class=\"edgePaths\"><path d=\"M103.484,67L103.484,71.167C103.484,75.333,103.484,83.667,103.55,91.2C103.616,98.734,103.748,105.467,103.814,108.834L103.88,112.201\" id=\"L-SA_Start-SA_SearchNode-0\" class=\" edge-thickness-normal edge-pattern-solid flowchart-link LS-SA_Start LE-SA_SearchNode\" style=\"fill:none;\" marker-end=\"url(#mermaid-svg_flowchart-pointEnd)\"/><path d=\"M103.984,151.5L103.901,155.583C103.818,159.667,103.651,167.833,103.568,175.2C103.484,182.567,103.484,189.133,103.484,192.417L103.484,195.7\" id=\"L-SA_SearchNode-SA_FinalState-0\" class=\" edge-thickness-normal edge-pattern-solid flowchart-link LS-SA_SearchNode LE-SA_FinalState\" style=\"fill:none;\" marker-end=\"url(#mermaid-svg_flowchart-pointEnd)\"/></g><g class=\"edgeLabels\"><g class=\"edgeLabel\"><g class=\"label\" transform=\"translate(0, 0)\"><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"edgeLabel\"></span></div></foreignObject></g></g><g class=\"edgeLabel\"><g class=\"label\" transform=\"translate(0, 0)\"><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"edgeLabel\"></span></div></foreignObject></g></g></g><g class=\"nodes\"><g class=\"node default default flowchart-label\" id=\"flowchart-SA_Start-8\" data-node=\"true\" data-id=\"SA_Start\" transform=\"translate(103.484375, 50)\"><rect class=\"basic label-container\" style=\"\" rx=\"5\" ry=\"5\" x=\"-25.0078125\" y=\"-17\" width=\"50.015625\" height=\"34\"/><g class=\"label\" style=\"\" transform=\"translate(-17.5078125, -9.5)\"><rect/><foreignObject width=\"35.015625\" height=\"19\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">Start</span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"flowchart-SA_SearchNode-9\" data-node=\"true\" data-id=\"SA_SearchNode\" transform=\"translate(103.484375, 134)\"><polygon points=\"8.5,0 112.46875,0 120.96875,-17 112.46875,-34 8.5,-34 0,-17\" class=\"label-container\" transform=\"translate(-60.484375,17)\" style=\"\"/><g class=\"label\" style=\"\" transform=\"translate(-44.484375, -9.5)\"><rect/><foreignObject width=\"88.96875\" height=\"19\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">Search Node</span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"flowchart-SA_FinalState-10\" data-node=\"true\" data-id=\"SA_FinalState\" transform=\"translate(103.484375, 218)\"><rect class=\"basic label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-46.0859375\" y=\"-17\" width=\"92.171875\" height=\"34\"/><g class=\"label\" style=\"\" transform=\"translate(-38.5859375, -9.5)\"><rect/><foreignObject width=\"77.171875\" height=\"19\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">Final State</span></div></foreignObject></g></g></g></g><g class=\"node default default flowchart-label\" id=\"flowchart-DA_Start-1\" data-node=\"true\" data-id=\"DA_Start\" transform=\"translate(111.03125, 363)\"><rect class=\"basic label-container\" style=\"\" rx=\"5\" ry=\"5\" x=\"-25.0078125\" y=\"-17\" width=\"50.015625\" height=\"34\"/><g class=\"label\" style=\"\" transform=\"translate(-17.5078125, -9.5)\"><rect/><foreignObject width=\"35.015625\" height=\"19\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">Start</span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"flowchart-DA_DelegateNode-2\" data-node=\"true\" data-id=\"DA_DelegateNode\" transform=\"translate(163.02734375, 447)\"><polygon points=\"8.5,0 128.25,0 136.75,-17 128.25,-34 8.5,-34 0,-17\" class=\"label-container\" transform=\"translate(-68.375,17)\" style=\"\"/><g class=\"label\" style=\"\" transform=\"translate(-52.375, -9.5)\"><rect/><foreignObject width=\"104.75\" height=\"19\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">Delegate Node</span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"flowchart-DA_FinalState-3\" data-node=\"true\" data-id=\"DA_FinalState\" transform=\"translate(163.02734375, 531)\"><rect class=\"basic label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-46.0859375\" y=\"-17\" width=\"92.171875\" height=\"34\"/><g class=\"label\" style=\"\" transform=\"translate(-38.5859375, -9.5)\"><rect/><foreignObject width=\"77.171875\" height=\"19\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">Final State</span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"flowchart-QueryNode-0\" data-node=\"true\" data-id=\"QueryNode\" transform=\"translate(71.6875, 126)\"><polygon points=\"8.5,0 65.890625,0 74.390625,-17 65.890625,-34 8.5,-34 0,-17\" class=\"label-container\" transform=\"translate(-37.1953125,17)\" style=\"\"/><g class=\"label\" style=\"\" transform=\"translate(-21.1953125, -9.5)\"><rect/><foreignObject width=\"42.390625\" height=\"19\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">Query</span></div></foreignObject></g></g></g></g></g></svg>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mermaid as md\n",
    "from mermaid.graph import Graph\n",
    "\n",
    "graph: Graph = Graph('example', \"\"\"\n",
    "flowchart TD\n",
    "    QueryNode{{\"Query\"}}\n",
    "    subgraph DA[\"Delegation Agent\"]\n",
    "        DA_Start(Start)\n",
    "        DA_DelegateNode{{\"Delegate Node\"}}\n",
    "        DA_FinalState[\"Final State\"]\n",
    "\n",
    "        DA_Start --> DA_DelegateNode\n",
    "        DA_DelegateNode --> DA_FinalState\n",
    "    end\n",
    "\n",
    "    subgraph SA[\"Search Agent\"]\n",
    "        SA_Start(Start)\n",
    "        SA_SearchNode{{\"Search Node\"}}\n",
    "        SA_FinalState[\"Final State\"]\n",
    "\n",
    "        SA_Start --> SA_SearchNode\n",
    "        SA_SearchNode --> SA_FinalState\n",
    "    end\n",
    "\n",
    "    QueryNode --> DA_Start\n",
    "    DA_DelegateNode -.->|Ask/Search| SA\n",
    "    SA -.->|Response/Result| DA\n",
    "\n",
    "    classDef agent fill:#f9f,stroke:#333,stroke-width:2px;\n",
    "    class DA,SA agent;\n",
    "\"\"\")\n",
    "graphe: md.Mermaid = md.Mermaid(graph)\n",
    "graphe"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-05T05:31:44.062149500Z",
     "start_time": "2024-05-05T05:31:43.690321700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-05T05:31:44.064777700Z",
     "start_time": "2024-05-05T05:31:44.062149500Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
